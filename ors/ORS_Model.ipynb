{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "akbiDVKh71s8"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import itertools\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def parse_rules_from_file(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "        rules = []\n",
        "        positive_count = 0\n",
        "        negative_count = 0\n",
        "\n",
        "        for line in lines:\n",
        "            if positive_count >= 4 and negative_count >= 4:\n",
        "                break\n",
        "            parts = line.split('<--')\n",
        "            label = parts[0].strip().lower()\n",
        "            condition_part = parts[1].strip()\n",
        "            conditions = condition_part.split(', ')\n",
        "            rule_dict = {'label': label}\n",
        "\n",
        "            for condition in conditions:\n",
        "                rule_dict[condition] = 0 if 'inv_' in condition or 'task_' in condition else 1\n",
        "\n",
        "            if label == 'positive' and positive_count < 4:\n",
        "                rules.append(rule_dict)\n",
        "                positive_count += 1\n",
        "            elif label == 'negative' and negative_count < 4:\n",
        "                rules.append(rule_dict)\n",
        "                negative_count += 1\n",
        "\n",
        "    return rules\n",
        "\n",
        "\n",
        "def load_data(file_path):\n",
        "    with open(file_path, 'r') as json_file:\n",
        "        return json.load(json_file)\n",
        "\n",
        "def split_data(data, train_frac=0.5, validate_frac=0.25):\n",
        "    random.shuffle(data)\n",
        "    n = len(data)\n",
        "    train_end = int(n * train_frac)\n",
        "    validate_end = train_end + int(n * validate_frac)\n",
        "    return data[:train_end], data[train_end:validate_end], data[validate_end:]\n",
        "import random\n",
        "\n",
        "def split_data(data, train_frac=0.8, validate_frac=0.1):\n",
        "    \"\"\"\n",
        "    Splits the data into train, validation, and test sets while maintaining original indices.\n",
        "\n",
        "    Args:\n",
        "    data (list): The dataset to be split.\n",
        "    train_frac (float): Fraction of the dataset to be used as the training set.\n",
        "    validate_frac (float): Fraction of the dataset to be used as the validation set.\n",
        "\n",
        "    Returns:\n",
        "    tuple: Three lists representing the train, validation, and test datasets.\n",
        "    \"\"\"\n",
        "    indices = list(range(len(data)))\n",
        "    random.shuffle(indices)\n",
        "\n",
        "    train_end = int(len(data) * train_frac)\n",
        "    validate_end = train_end + int(len(data) * validate_frac)\n",
        "\n",
        "    train_indices = indices[:train_end]\n",
        "    validate_indices = indices[train_end:validate_end]\n",
        "    test_indices = indices[validate_end:]\n",
        "\n",
        "    train_data = [data[i] for i in train_indices]\n",
        "    validate_data = [data[i] for i in validate_indices]\n",
        "    test_data = [data[i] for i in test_indices]\n",
        "\n",
        "    return train_data, validate_data, test_data, test_indices\n",
        "\n",
        "\n",
        "processed_data = load_data('/content/processed_transformed_data_json.json')\n",
        "\n",
        "\n",
        "high_confidence_rules = parse_rules_from_file(\"/content/Corrected_High_Confidence_Rules.txt\")\n",
        "converted_rrl_sarp_rules = parse_rules_from_file(\"/content/corrected_converted_rrl_sarp.txt\")\n",
        "all_rule_conditions = high_confidence_rules + converted_rrl_sarp_rules\n",
        "\n",
        "def generate_combinations(rule_conditions, min_components):\n",
        "    combinations = []\n",
        "    for r in range(min_components, len(rule_conditions) + 1):\n",
        "        combinations.extend(itertools.combinations(rule_conditions, r))\n",
        "    return combinations\n",
        "\n",
        "\n",
        "\n",
        "def apply_rule(data, conditions, operation='AND', default_label='negative'):\n",
        "\n",
        "    rule_label = conditions.pop('label', default_label)\n",
        "    if data.get('label', default_label) != rule_label:\n",
        "        return 'not ' + rule_label, data.get('actual_label', 'negative'), 0\n",
        "\n",
        "    total_conditions = len(conditions)\n",
        "    matched_conditions = sum(1 for key, value in conditions.items() if data.get(key, 0) == value)\n",
        "    matched_all = all(data.get(key, 0) == value for key, value in conditions.items()) if operation == 'AND' else any(data.get(key, 0) == value for key, value in conditions.items())\n",
        "\n",
        "    predicted_label = rule_label if matched_all else 'not ' + rule_label\n",
        "    confidence = (matched_conditions / total_conditions) * 100\n",
        "    actual_label = data.get('actual_label', 'negative')\n",
        "    return predicted_label, actual_label, confidence\n",
        "\n",
        "\n",
        "def evaluate_combinations_by_range(data_samples, rule_conditions, min_components):\n",
        "    rule_results = []\n",
        "    index_label_pairs = {}\n",
        "    for index, data_sample in enumerate(data_samples):\n",
        "        for min_comp in range(1, min_components + 1):\n",
        "            combinations = generate_combinations(rule_conditions, min_comp)\n",
        "            for combination in combinations:\n",
        "                flattened_conditions = {k: v for d in combination for k, v in d.items()}\n",
        "                for operation in ['AND', 'OR']:\n",
        "                    label, actual_label, confidence = apply_rule(data_sample, flattened_conditions, operation)\n",
        "                    rule_results.append((label, actual_label, confidence))\n",
        "                    if index not in index_label_pairs or confidence > index_label_pairs[index][1]:\n",
        "                        index_label_pairs[index] = (label, confidence)\n",
        "\n",
        "    rule_results.sort(key=lambda x: x[2], reverse=True)\n",
        "    top_rules = rule_results[:int(len(rule_results) * 0.0001)]\n",
        "\n",
        "    tp, fp, fn, tn = 0, 0, 0, 0\n",
        "    total_confidence = 0\n",
        "    for label, actual_label, confidence in top_rules:\n",
        "        total_confidence += confidence\n",
        "        if label == actual_label:\n",
        "            if label.startswith('not '):\n",
        "                tn += 1\n",
        "            else:\n",
        "                tp += 1\n",
        "        else:\n",
        "            if label.startswith('not '):\n",
        "                fn += 1\n",
        "            else:\n",
        "                fp += 1\n",
        "\n",
        "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    accuracy = (tp + tn) / (tp + tn + fp + fn) if (tp + tn + fp + fn) > 0 else 0\n",
        "    interpretability = 1 / min_components\n",
        "    overall_confidence = total_confidence / len(top_rules) if top_rules else 0\n",
        "\n",
        "    return overall_confidence, precision, recall, f1_score, accuracy, interpretability, index_label_pairs\n",
        "\n",
        "\n",
        "def find_best_min_component(validate_data, rule_conditions, min_range, max_range, weight_interpretability=0.0):\n",
        "    best_score = 0\n",
        "    best_min_comp = min_range\n",
        "    for min_comp in range(min_range, max_range + 1):\n",
        "        result = evaluate_combinations_by_range(validate_data, rule_conditions, min_comp)\n",
        "        overall_confidence, precision, recall, f1_score, accuracy, interpretability, _ = result\n",
        "        score = (accuracy * (1 - weight_interpretability)) + (interpretability * weight_interpretability)\n",
        "        if overall_confidence > best_score:\n",
        "            best_score = overall_confidence\n",
        "            best_min_comp = min_comp\n",
        "    return best_min_comp\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "min_comp=0\n",
        "results = []\n",
        "for _ in range(10):\n",
        "    train_data, validate_data, test_data, test_indices = split_data(processed_data,0.5,0.25)\n",
        "    best_min_components = find_best_min_component(train_data, all_rule_conditions, 1, 10)\n",
        "    _, precision, recall, f1_score, accuracy, interpretability, indexed_label_pairs = evaluate_combinations_by_range(test_data, all_rule_conditions, best_min_components)\n",
        "    original_index_label_pairs = [(test_indices[i], label) for i, (label, _) in indexed_label_pairs.items()]\n",
        "\n",
        "    file_name = f'/content/test_predictions_{min_comp}.json'\n",
        "    with open(file_name, 'w') as f:\n",
        "        json.dump(original_index_label_pairs, f, indent=4)\n",
        "    print(f'Results saved in {file_name}')\n",
        "    overall_confidence, precision, recall, f1_score, accuracy, interpretability, _ = evaluate_combinations_by_range(test_data, all_rule_conditions, best_min_components)\n",
        "    results.append([overall_confidence, precision, recall, f1_score, accuracy, interpretability])\n",
        "\n",
        "    results_array = np.array([result[:-1] for result in results])\n",
        "    mean_metrics = np.mean(results_array, axis=0)\n",
        "    std_metrics = np.std(results_array, axis=0)\n",
        "    min_comp=min_comp+1\n",
        "    print(results_array)\n",
        "    print(std_metrics)\n",
        "\n",
        "\n"
      ]
    }
  ]
}